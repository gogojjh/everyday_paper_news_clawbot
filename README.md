# ğŸ“š Everyday Paper & Repo News

æ¯æ—¥è‡ªåŠ¨æ¨é€ ArXiv è®ºæ–‡ä»¥åŠ GitHub å’Œ Hugging Face ä¸Šçš„æœºå™¨äººå­¦ç›¸å…³å¼€æºä»“åº“å’Œæ¨¡å‹ã€‚

---

## ğŸ“„ ArXiv å†å²æŠ¥å‘Š

| æ—¥æœŸ | æŠ¥å‘Šé“¾æ¥ | è®ºæ–‡æ•°é‡ |
|------|----------|----------|
| 2026-02-23 | [arxiv_daily_report_2026-02-23.md](./arxiv_daily_report_2026-02-23.md) | 15 ç¯‡ |
| 2026-02-22 | [arxiv_daily_report_2026-02-22.md](./arxiv_daily_report_2026-02-22.md) | 11 ç¯‡ |

---

## ğŸ—‚ï¸ Repo å†å²æŠ¥å‘Š

| æ—¥æœŸ | æŠ¥å‘Šé“¾æ¥ | ä»“åº“/æ¨¡å‹æ•°é‡ |
|------|----------|--------------|
| 2026-02-23 | [repo_daily_report_2026-02-23.md](./repo_daily_report_2026-02-23.md) | 1 |
| 2026-02-22 | [repo_daily_report_2026-02-22.md](./repo_daily_report_2026-02-22.md) | 1 |

---

## ğŸ” æœç´¢èŒƒå›´

### ArXiv è®ºæ–‡åˆ†ç±»
| åˆ†ç±» | è¯´æ˜ |
|------|------|
| **Humanoid & Legged Robots** | äººå½¢æœºå™¨äººã€å››è¶³æœºå™¨äººã€è¿åŠ¨æ§åˆ¶ |
| **Visual Navigation & Mapping** | è§†è§‰å¯¼èˆªã€SLAMã€å»ºå›¾ |
| **Lifelong SLAM** | é•¿æœŸ SLAMã€æŒç»­å»ºå›¾ |
| **Robot Navigation & Planning** | å¯¼èˆªã€è·¯å¾„è§„åˆ’ã€è¿åŠ¨è§„åˆ’ |
| **Articulated Objects** | å…³èŠ‚ç‰©ä½“æ“ä½œã€affordance |
| **Human-Robot Interaction** | äººæœºäº¤äº’ã€åä½œ |

### Repo æœç´¢å¹³å°
| åˆ†ç±» | è¯´æ˜ |
|------|------|
| **3D Reconstruction** | 3D é‡å»ºã€NeRFã€Gaussian Splatting |
| **Navigation** | æœºå™¨äººå¯¼èˆªã€è·¯å¾„è§„åˆ’ã€è§†è§‰å¯¼èˆª |
| **VLA** | Vision-Language-Action æ¨¡å‹ |

---

## ğŸ”§ é…ç½®è¯´æ˜

- **æ›´æ–°é¢‘ç‡**: æ¯å¤© 8:00 è‡ªåŠ¨æ›´æ–°
- **æœç´¢å¹³å°**: ArXiv + GitHub + Hugging Face
- **GitHub ç”¨æˆ·**: gogojjh
- **ç­›é€‰æ ‡å‡†**: 
  - Hugging Face: ä¸‹è½½é‡ > 500
  - GitHub: stars > 300, issues > 10, 6 ä¸ªæœˆå†…æ›´æ–°

---

## ğŸ”‘ ArXiv æœç´¢å…³é”®è¯

1. **SLAM & Mapping**: lifelong SLAM, long-term SLAM, continuous SLAM, persistent SLAM
2. **Navigation**: robot navigation, path planning, motion planning, autonomous navigation
3. **Manipulation**: articulated object, cabinet opening, affordance, grasp detection
4. **CV&AI**: world model, 3d reconstruction, vision-language-action model, vision-language model

---

*æœ€åæ›´æ–°ï¼š2026-02-23*
